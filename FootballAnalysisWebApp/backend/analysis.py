from utils import read_video, save_video
from team_assigner import TeamAssigner
from player_ball_assigner import PlayerBallAssigner
from camera_movement_estimator import CameraMovementEstimator
from tracker import BallTracker, FieldTracker, Tracker
import numpy as np
import pickle
import pandas as pd
import event_analysis
import cv2
import os


def detect_game_pauses(tracks, ball_key='ball', threshold_seconds=0.5, fps=30):
    """
    D√©tecte les arr√™ts de jeu si la balle est immobile pendant plus de `threshold_seconds` secondes.
    
    Args:
        tracks (dict): Donn√©es de tracking (comme celles dans le fichier .pkl).
        ball_key (str): Cl√© utilis√©e pour identifier les donn√©es de la balle.
        threshold_seconds (float): Dur√©e minimale (en secondes) pour qu'un arr√™t de jeu soit d√©tect√©.
        fps (int): Images par seconde de la vid√©o.
    
    Returns:
        list: Liste des plages de frames o√π un arr√™t de jeu a √©t√© d√©tect√©.
    """
    pauses = []
    pause_start = None
    consecutive_static_frames = 0
    threshold_frames = int(threshold_seconds * fps)

    # V√©rifiez que tracks est un dictionnaire
    if not isinstance(tracks, dict):
        raise ValueError("tracks doit √™tre un dictionnaire")

    # R√©cup√©rer les positions de la balle
    ball_positions = tracks.get(ball_key, [])
    if not ball_positions:
        print("Aucune donn√©e de position de la balle trouv√©e dans les tracks.")
        return pauses

    # Extraire les positions de la balle en tant que DataFrame
    ball_positions = [frame_data.get(1, {}).get('bbox', []) for frame_data in ball_positions]
    if not any(ball_positions):
        print("Les donn√©es de la balle sont vides.")
        return pauses

    # Cr√©er un DataFrame avec les positions de la balle
    df_ball_positions = pd.DataFrame(ball_positions, columns=['x1', 'y1', 'x2', 'y2'])
    df_ball_positions['frame_num'] = range(len(ball_positions))  # Ajouter les num√©ros de frame
    print("Positions de la balle (DataFrame) :")
    print(df_ball_positions)

    # V√©rifier les d√©placements de la balle
    for i in range(1, len(df_ball_positions)):
        prev_center = np.array([(df_ball_positions.loc[i - 1, 'x1'] + df_ball_positions.loc[i - 1, 'x2']) / 2,
                                (df_ball_positions.loc[i - 1, 'y1'] + df_ball_positions.loc[i - 1, 'y2']) / 2])
        curr_center = np.array([(df_ball_positions.loc[i, 'x1'] + df_ball_positions.loc[i, 'x2']) / 2,
                                (df_ball_positions.loc[i, 'y1'] + df_ball_positions.loc[i, 'y2']) / 2])
        movement = np.linalg.norm(curr_center - prev_center)

        print(f"Frame {df_ball_positions.loc[i, 'frame_num']}: Movement = {movement}")

        # V√©rifier si la balle est immobile (ou presque)
        if movement < 10:  # R√©duire le seuil de mouvement
            consecutive_static_frames += 1
            if pause_start is None:
                pause_start = df_ball_positions.loc[i - 1, 'frame_num']
        else:
            # Si un mouvement est d√©tect√©, v√©rifier la dur√©e de la pause
            if consecutive_static_frames >= threshold_frames:
                pause_end = df_ball_positions.loc[i - 1, 'frame_num']
                pauses.append((pause_start, pause_end))
            consecutive_static_frames = 0
            pause_start = None

    # Ajouter la derni√®re pause si elle n'a pas √©t√© enregistr√©e
    if consecutive_static_frames >= threshold_frames:
        pause_end = df_ball_positions.loc[len(df_ball_positions) - 1, 'frame_num']
        pauses.append((pause_start, pause_end))

    return pauses





def analyse_video(video_path):
    # Load the YOLOv5 model
    video_name = video_path.split('/')[-1]
    video_frames, height, width = read_video(video_path)

    # Create a tracker object
    tracker = Tracker('weights/best.pt')
    # model line tracking football-field-detection-f07vi/15
    tracks = tracker.get_object_tracks(video_frames, read_from_strub=True, stub_path='stubs/'+video_name+'_track_stub.pkl')
    tracker.add_position_to_tracks(tracks)
    field_tracker = FieldTracker('weights/best_field-detector.pt')
    field_tracks = field_tracker.track_field_lines(video_frames,read_from_strub=True,stub_path='stubs/'+video_name+'_field_track_stub.pkl')
    print(field_tracks)
    # camera movement estimation
    # Interpolate Ball Positions
    #tracks["ball"] = interpolate_ball_positions(tracks["ball"])
    #camera_movement_estimator = CameraMovementEstimator(video_frames[0])
    #camera_movement_estimator.add_adjust_positions_to_tracks(tracks, camera_movement_per_frame)
    #camera_movement_per_frame = camera_movement_estimator.get_camera_movement(video_frames, read_from_stub=True, stub_path='stubs/'+video_name+'_camera_movement_stub.pkl')
    ball_tracker = BallTracker()
    tracks["ball"] = ball_tracker.interpolate_ball_positions(tracks["ball"])
    tracks["ball"] = ball_tracker.interpolate_ball_positions_cubic_spline(tracks["ball"])
    # Assign Player Teams
    # Initialize TeamAssigner
    team_assigner = TeamAssigner()
    team_assigner.assign_team_color(video_frames[0], tracks['players'][0])


# Assign teams to each track
    team_assigner.assign_team_color(video_frames[0], tracks['players'][0])
    for frame_num, player_track in enumerate(tracks['players']):
        frame = video_frames[frame_num]
        for player_id, track in player_track.items():
            bbox = track['bbox']
            team = team_assigner.get_player_team(frame, bbox, player_id)
            tracks['players'][frame_num][player_id]['team'] = team


# Collect player colors grouped by team
    team_player_colors = {}
    for frame_num, player_track in enumerate(tracks['players']):
        frame = video_frames[frame_num]
        for player_id, track in player_track.items():
            team = track['team']
            bbox = track['bbox']
            image = frame[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]
            color = get_average_color(image,intensity_factor=0.5)
            if team not in team_player_colors:
                team_player_colors[team] = []
            team_player_colors[team].append(color)

# Compute average team colors
    team_colors = {}
    for team, colors in team_player_colors.items():
        team_colors[team] = np.mean(colors, axis=0)

# Assign team_colors to each track
    for frame_num, player_track in enumerate(tracks['players']):
        for player_id, track in player_track.items():
            team = track['team']
            tracks['players'][frame_num][player_id]['team_color'] = team_colors[team]
    team_assigner.team_colors = team_colors
    # Set team_colors in TeamAssigner


    # Draw annotations

    player_assigner = PlayerBallAssigner()
    team_ball_control = []
    for frame_num, player_track in enumerate(tracks['players']):
        ball_bbox = tracks['ball'][frame_num][1]['bbox']
        if frame_num in tracks['ball'] and 1 in tracks['ball'][frame_num] and 'bbox' in tracks['ball'][frame_num][1]:
            ball_bbox = tracks['ball'][frame_num][1]['bbox']
            assigned_player = player_assigner.assign_ball_to_player(player_track, ball_bbox)
        else:
            continue 

        if assigned_player != -1:
            tracks['players'][frame_num][assigned_player]['has_ball'] = True
            team_ball_control.append(tracks['players'][frame_num][assigned_player]['team'])
        else:
            if team_ball_control:
                team_ball_control.append(team_ball_control[-1])
    team_ball_control = np.array(team_ball_control)

    # Detect game pauses
    print("D√©tection des arr√™ts de jeu...")
    pauses = detect_game_pauses(tracks, ball_key="ball", threshold_seconds=1, fps=30)
    print("Arr√™ts de jeu d√©tect√©s :", pauses)
    for start, end in pauses:
        duration = (end - start) / 30  # Convertir les frames en secondes
        print(f"Arr√™t de jeu entre les frames {start} et {end} (dur√©e : {duration:.2f} secondes)")
    
       # Display and save paused frames
    print("Affichage des frames en pause...")
    display_paused_frames(video_path, pauses, video_frames, tracks, output_folder="output_frames")
    print("Affichage termin√©.")


    #Draw output
    output_video_frames = field_tracker.annotate_field_lines(video_frames, field_tracks['field_lines'])
    output_video_frames = tracker.draw_annotations(video_frames, tracks, team_ball_control, pauses)
    output_video_frames = camera_movement_estimator.draw_camera_movement(output_video_frames, camera_movement_per_frame)
    # Save the video with the bounding boxes
    save_video(output_video_frames, 'output/video_output.mp4', height, width)

def get_average_color(image,intensity_factor=1.5):
    top_half_image = image[0:int(image.shape[0]/2), :]
    average_color = np.mean(top_half_image, axis=(0, 1))
    
    # Amplify the color intensit
    
    return average_color

def display_paused_frames(video_path, pauses,video_frames, tracks,  output_folder="output_frames", show_frames=True):
    """
    Affiche et enregistre les frames o√π un arr√™t de jeu est d√©tect√©.
    D√©sactive cv2.imshow() si aucun affichage graphique n'est disponible.
    """
    # Cr√©er le dossier de sortie s'il n'existe pas
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
        print(f"‚úÖ Dossier de sortie cr√©√© : {output_folder}")

    # Ouvrir la vid√©o
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"‚ùå Erreur : Impossible d'ouvrir la vid√©o √† l'emplacement {video_path}")
        return

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    print(f"üìπ Vid√©o charg√©e : {frame_count} frames, {fps} FPS")

    # V√©rifier si l'affichage graphique est disponible (d√©sactiver imshow si n√©cessaire)
    no_display = os.environ.get("DISPLAY") is None  # V√©rifie si DISPLAY est d√©fini (Linux/macOS)
    
    # Parcourir les pauses d√©tect√©es
    for i, (start, end) in enumerate(pauses):
        print(f"üîç Traitement de la pause {i} : frames {start} √† {end}")
        for frame_num in range(start, min(end + 1, frame_count)):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
            ret, frame = cap.read()
            if not ret:
                print(f"‚ùå Erreur : Impossible de lire la frame {frame_num}")
                continue

            # Enregistrer la frame
            frame_path = os.path.join(output_folder, f"pause_{i}_frame_{frame_num}.jpg")
            cv2.imwrite(frame_path, frame)
            print(f"‚úÖ Image enregistr√©e : {frame_path}")

            # Afficher la frame uniquement si un affichage est disponible
            if not no_display and show_frames:
                cv2.imshow(f"Pause {i} - Frame {frame_num}", frame)
                cv2.waitKey(300)

    cap.release()
    cv2.destroyAllWindows()



    # Event detection
    events_df = event_analysis.parse_xml_results('Annotations_AtomicEvents_Results.xml')
    ground_df = event_analysis.parse_ground_truth('Annotations_AtomicEvents_Results.xml')


 



    


